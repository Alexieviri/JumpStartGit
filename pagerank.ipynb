{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "pagerank.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz-ya6Q-k0lD"
      },
      "source": [
        "# PageRank на Spark RDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5pehVSck0lE"
      },
      "source": [
        "### Шаг №1\n",
        "Создайте `SparkContext`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZgrWExZk0lE"
      },
      "source": [
        "import random\n",
        "SPARK_UI_PORT = random.choice(range(10000, 10200))\n",
        "print(f\"Spark UI port: {SPARK_UI_PORT}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KweqqwoRk0lF"
      },
      "source": [
        "from pyspark import SparkConf, SparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtWi44BGk0lF"
      },
      "source": [
        "conf = SparkConf()\n",
        "conf.set(\"spark.ui.port\", SPARK_UI_PORT)\n",
        "conf.set(\"spark.driver.memory\", \"512m\")\n",
        "conf.set(\"spark.executor.instances\", \"2\")\n",
        "conf.set(\"spark.executor.cores\", \"1\")\n",
        "\n",
        "sc = SparkContext(master=\"yarn\", conf=conf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVGotGNHk0lG"
      },
      "source": [
        "### Шаг №2\n",
        "1. Прочитайте граф из файла `/data/spark/lecture05/graph.tsv`\n",
        "2. Создайте RDD, в которой граф будет представлен парами вершин\n",
        "3. Убедитесь, что граф совпадает с рисунком на доске"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5G7KyCbk0lG"
      },
      "source": [
        "raw_graph = sc.textFile(\"/data/spark/lecture05/graph.tsv\")\n",
        "graph = raw_graph.map(lambda x: tuple(x.split(\"\\t\")))\\\n",
        "                 .distinct()\\\n",
        "                 .cache()\n",
        "graph.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e-ctxqdk0lH"
      },
      "source": [
        "### Шаг №3\n",
        "Создайте RDD с первоначальными pagerank всех уникальных вершин"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnY2AVBvk0lH"
      },
      "source": [
        "vertices = graph.map(lambda x: x[0]).union(graph.map(lambda x: x[1])).distinct()\n",
        "\n",
        "num_vertices = vertices.count()\n",
        "\n",
        "ranks = vertices.map(lambda x: (x, 1 / num_vertices))\n",
        "ranks.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTRtyJHk0lH"
      },
      "source": [
        "### Шаг №4\n",
        "Создайте RDD, которая берет RDD с вершинами, объединяет ее с RDD с pagerank. В результате должна получится PairRDD, где ключ - это уникальная вершина, а значение - это все вершины, на которые она ссылаются и ее текущий pagerank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuMXYUJXk0lI"
      },
      "source": [
        "links = graph.groupByKey().mapValues(list).cache()\n",
        "\n",
        "contributions = links.join(ranks)\n",
        "contributions.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgGIpOqZk0lI"
      },
      "source": [
        "### Шаг №5\n",
        "Реализуйте функцию, которая рассчитывает pagerank для всех вершин, на которые ссылается данная вершина. Функция должна быть итератором, который возвращает вершину и ее pagerank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-BKnJFuk0lI"
      },
      "source": [
        "def computeContribs(neighbours, pagerank):\n",
        "    num = len(neighbours)\n",
        "    \n",
        "    for n in neighbours:\n",
        "        yield (n, pagerank / num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp66Mc6ek0lI"
      },
      "source": [
        "### Шаг №6\n",
        "Обновите RDD с pagerank значениями, посчитанными с помощью функции из предыдущего шага"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrgEF-2ik0lJ"
      },
      "source": [
        "ranks = contributions.flatMap(lambda x: computeContribs(x[1][0], x[1][1]))\\\n",
        "                     .reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "ranks.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFH8d9Mrk0lJ"
      },
      "source": [
        "### Шаг №7\n",
        "Напишите цикл, который проводит несколько итераций вычисления pagerank и на каждой печатает номер итерации и текущие pagerank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T89HxOB8k0lJ"
      },
      "source": [
        "iterations = 10\n",
        "raw_graph = sc.textFile(\"/data/spark/lecture05/graph.tsv\")\n",
        "graph = raw_graph.map(lambda x: tuple(x.split(\"\\t\")))\\\n",
        "                 .distinct()\\\n",
        "                 .cache()\n",
        "vertices = graph.map(lambda x: x[0]).union(graph.map(lambda x: x[1])).distinct()\n",
        "num_vertices = vertices.count()\n",
        "ranks = vertices.map(lambda x: (x, 1 / num_vertices))\n",
        "\n",
        "for i in range(iterations):\n",
        "    links = graph.groupByKey().mapValues(list).cache()\n",
        "    contributions = links.join(ranks)\n",
        "    ranks = contributions.flatMap(lambda x: computeContribs(x[1][0], x[1][1]))\\\n",
        "                         .reduceByKey(lambda x, y: x + y)\n",
        "    print(\"Iteration {0}: current pagerank {1}\".format(i, sorted(ranks.collect(), key=lambda x: x[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m91io2gk0lJ"
      },
      "source": [
        "### Шаг №8\n",
        "Не забудьте остановить SparkContext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45qzvIMsk0lJ"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRU7aXMKk0lK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}